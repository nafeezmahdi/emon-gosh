export const sidebarData = {
  imageLink:
    "https://media.licdn.com/dms/image/v2/D4D03AQGrsBzp0aX0cg/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1679467903252?e=1734566400&v=beta&t=usAGBnAeAsCU_BnY1uE6kSN4dwxtBpVodjFMo3PrwWg",
  name: "Emon Gosh",
  bio: "PhD Student @ UC Riverside || LLMs, AI Safety, Bias &amp; Fairness",
  location: "Riverside",
  mail: "sshibli745@gmail.com",
  scholar: "https://scholar.google.com/citations?user=GBaSF7MAAAAJ&amp;hl=en",
  linkedIn: "https://www.linkedin.com/in/shahariar-shibli",
  github: "https://github.com/shahariar-shibli",
};

export const ResearchPageData = {
  infoText:
    "My research delves into the realms of natural language processing (NLP), encompassing both generation (NLG) and understanding (NLU). I aim to leverage contemporary NLP applications across diverse languages and fields in my research endeavors. Some of the research areas I have worked on or am currently working on are listed below.",
  items: [
    {
      id: 1,
      title: "1. AI Safety on T2I",
      text: " Text-to-Image (T2I) generation models such as Stable Diffusion, DALL-E2, Imagen, and ediff-i have made steady progress in the field of image generation by bridging the semantic gap between textual descriptions and visual representations. Unlike traditional methods reliant solely on pixel manipulation, these models leverage multi-model alignments in latent spaces to interpret and synthesize complex visual content from textual prompts. Recent research shows that T2I models are vulnerable to adversarial perturbations in text prompts, such as inserting nonsensical words, phrases, or irrelevant characters, which can significantly bias the generated images. However, current adversarial attacks on T2I generation models, either manual heuristic-based methods or automatic gradient-based approaches are specifically targeting entities or objects (i.e., nouns) in text prompts, neglecting other parts of speech. Therefore, we aim to answer the following two research questions: ",
    },
    {
      id: 2,
      title: "1. AI Safety on T2I",
      text: " Text-to-Image (T2I) generation models such as Stable Diffusion, DALL-E2, Imagen, and ediff-i have made steady progress in the field of image generation by bridging the semantic gap between textual descriptions and visual representations. Unlike traditional methods reliant solely on pixel manipulation, these models leverage multi-model alignments in latent spaces to interpret and synthesize complex visual content from textual prompts. Recent research shows that T2I models are vulnerable to adversarial perturbations in text prompts, such as inserting nonsensical words, phrases, or irrelevant characters, which can significantly bias the generated images. However, current adversarial attacks on T2I generation models, either manual heuristic-based methods or automatic gradient-based approaches are specifically targeting entities or objects (i.e., nouns) in text prompts, neglecting other parts of speech. Therefore, we aim to answer the following two research questions: ",
    },
  ],
};

export const PublicationPageData = {
  scholarLink:
    "https://scholar.google.com/citations?hl=en&amp;user=GBaSF7MAAAAJ&amp;view_op=list_works&amp;sortby=pubdate",
  data: [
    {
      id: crypto.randomUUID(),
      year: "2024",
      itemsData: [
        {
          id: crypto.randomUUID(),
          title:
            "Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation",
          titleLink: "https://arxiv.org/pdf/2409.15381",
          sideTitle: "Core A*",
          authors: ["G M Shahariar", "Jia Chen", "Jiachen Li", "Yue Dong"],
          type: "Journal",
          typeText: "EMNLP Findings",
          typeLinkText: "EMNLP 2024",
          typeLink: "https://2024.emnlp.org/",
          pdfLink: "",
          details:
            "Recent studies show that text-to-image (T2I) models are vulnerable to adversarial attacks, especially with noun perturbations in text prompts. In this study, we investigate the impact of adversarial attacks on different POS tags within text prompts on the images generated by T2I models. We create a high-quality dataset",
        },
      ],
    },
  ],
};
